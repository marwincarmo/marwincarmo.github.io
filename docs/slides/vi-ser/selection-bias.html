<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Understanding Model Selection Bias via Simulation</title>
    <meta charset="utf-8" />
    <meta name="author" content="Marwin M I B Carmo" />
    <script src="selection-bias_files/header-attrs/header-attrs.js"></script>
    <link href="selection-bias_files/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script src="selection-bias_files/xaringanExtra-progressBar/progress-bar.js"></script>
    <script src="selection-bias_files/fabric/fabric.min.js"></script>
    <link href="selection-bias_files/xaringanExtra-scribble/scribble.css" rel="stylesheet" />
    <script src="selection-bias_files/xaringanExtra-scribble/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#FF0000"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
    <link href="selection-bias_files/panelset/panelset.css" rel="stylesheet" />
    <script src="selection-bias_files/panelset/panelset.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="css/custom.css" type="text/css" />
    <link rel="stylesheet" href="css/scrollable.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Understanding Model Selection Bias via Simulation
## VI SER - International Seminar on Statistics with R
### Marwin M I B Carmo
### Department of Psychiatry, Faculty of Medicine, University of São Paulo, Brazil
### <img src ='img/fapesp-ipq.png' width = '30%'>

---









<style>.xe__progress-bar__container {
  top:0;
  opacity: 1;
  position:absolute;
  right:0;
  left: 0;
}
.xe__progress-bar {
  height: 0.25em;
  background-color: #c31919;
  width: calc(var(--slide-current) / var(--slide-total) * 100%);
}
.remark-visible .xe__progress-bar {
  animation: xe__progress-bar__wipe 200ms forwards;
  animation-timing-function: cubic-bezier(.86,0,.07,1);
}
@keyframes xe__progress-bar__wipe {
  0% { width: calc(var(--slide-previous) / var(--slide-total) * 100%); }
  100% { width: calc(var(--slide-current) / var(--slide-total) * 100%); }
}</style>

<div>
<style type="text/css">.xaringan-extra-logo {
width: 110px;
height: 128px;
z-index: 0;
background-image: url(img/logo.png);
background-size: contain;
background-repeat: no-repeat;
position: absolute;
top:1em;right:3em;
}
</style>
<script>(function () {
  let tries = 0
  function addLogo () {
    if (typeof slideshow === 'undefined') {
      tries += 1
      if (tries < 10) {
        setTimeout(addLogo, 100)
      }
    } else {
      document.querySelectorAll('.remark-slide-content:not(.my-title):not(.inverse):not(.hide_logo)')
        .forEach(function (slide) {
          const logo = document.createElement('div')
          logo.classList = 'xaringan-extra-logo'
          logo.href = null
          slide.appendChild(logo)
        })
    }
  }
  document.addEventListener('DOMContentLoaded', addLogo)
})()</script>
</div>

# Introduction

Much of the current research questions on behavioral and social sciences are investigated using statistical models.

Researchers who have a vague idea of the right model to answer their research questions and engage in a "data mining" process.

To determine which variables should be included in the model, a common solution is to resort to variable selection algorithms.

Often, the final model obtained through variable selection is interpreted as if it were prespecified.

---
# Why is it a problem?

The estimated results can be highly biased when the correct model is unknown prior to data analysis, and the same data set is used for:

1. variable selection; 
2. parameter estimation; 
3. statistical inferences

These procedures discards parameter estimates from the model, and the sampling distribution of the remaining regression parameters estimates gets distorted

---

In a multiple regression we estimate *partial regression coefficients*

`\begin{equation}
y_i = b_0 + b_1x_1 + b_2x_2 + \varepsilon
\end{equation}`

The regression coefficient for `\(x_i\)`, is model dependent:

`\begin{equation}
b_1 = \frac{r_{yx_1} - r_{yx_2}r_{x_1x_2}}{(1 - r_{x_1x_2}^2)} \times \frac{\sigma_y}{\sigma_{x_1}}
\end{equation}`

`\begin{equation}
b_2 = \frac{r_{yx_2} - r_{yx_1}r_{x_2x_1}}{(1 - r_{x_2x_1}^2)} \times \frac{\sigma_y}{\sigma_{x_2}}
\end{equation}`

Unless we have uncorrelated predictors (i.e. `\(r_{x_1x_2}\)` = 0), the value for any of the regression coefficients is determined by which other predictors are in the model:

`\begin{equation}
b_1 = \frac{r_{yx_1} - r_{yx_2} \times 0}{(1 - 0^2)} \times \frac{\sigma_y}{\sigma_{x_1}} = r_{yx_1} \times \frac{\sigma_y}{\sigma_{x_1}}
\end{equation}`

---

# Example 1

Consider a model for a response variable `\(y\)` with two potential regressors, `\(x\)` and `\(z\)`. Say we are interested in the relationship between `\(y\)` and `\(x\)` while holding `\(z\)` constant, that is, `\(\hat{\beta}_{yx\cdot z}\)`

`\begin{equation}
y_i = \beta_0 + \beta_1x_i + \beta_2z_i + \varepsilon_i
\end{equation}`


```r
reps &lt;-  1000
p &lt;- 2 # number of predictors
Sigma &lt;- matrix(.5, p, p) # correlation matrix
diag(Sigma) &lt;- 1
n &lt;-  250 # sample size
b0 &lt;- 0 # intercept (can be set to any value)
betas &lt;- rep(1, 2) 
error &lt;- rnorm(n, 0, sqrt(10))
coefs_a &lt;- cover &lt;- matrix(0, nrow = reps, ncol = 2) # defining the matrices to store simulation results
```

---

.panelset[
.panel[.panel-name[Code]


```r
for (i in seq(reps)) {
  # X is a matrix of regression coefficients
  X &lt;-  MASS::mvrnorm(n = n, rep(0, 2) , Sigma)
  # with the values randomly drawn in X, we'll estimate values for y
  y &lt;- as.numeric(cbind(1, X) %*% c(b0, betas) + error)
  Xy &lt;- as.data.frame( cbind(X, y))
  colnames(Xy) &lt;- c(c("x", "z"), "y")
  # fit a linear model with x and z to predict y
  fit &lt;- lm(y ~ ., data = Xy)
  coefs_a[i, ] &lt;- coef(fit)[-1] # save the regression coefficients
  cis &lt;- confint(fit)[-1,] # save the 95% CIs
  # if the true value is capture by the CI, sum 1, 0 otherwise 
  cover[i,] &lt;- ifelse(cis[,1] &lt; 1 &amp; cis[,2] &gt; 1, 1, 0)
}
colnames(coefs_a) &lt;- c("x", "z")
coefs_a &lt;- as.data.frame(coefs_a)
bias &lt;- coefs_a - betas
```

]
.panel[.panel-name[Results]

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Predictor &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Coverage &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Bias &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; x &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.941 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0053015 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; z &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.942 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.0016928 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;img src="selection-bias_files/figure-html/plot-ex1a-1.png" width="70%" style="display: block; margin: auto;" /&gt;
]
]
---



.panelset[
.panel[.panel-name[Code]

```r
for (i in seq(reps)) {
  X &lt;-  MASS::mvrnorm(n = n, rep(0, 2) , Sigma)
  y &lt;- as.numeric(cbind(1, X) %*% c(b0, betas) + rnorm(n, 0, sqrt(10)))
  Xy &lt;- as.data.frame( cbind(X, y))
  colnames(Xy) &lt;- c(c("x", "z"), "y")
* fit &lt;- lm(y ~ x, data = Xy)
  coefs_b[i, ] &lt;- coef(fit)[-1]
  cis &lt;- confint(fit)[-1,]
  cover[i,] &lt;- ifelse(cis[1] &lt; 1 &amp; cis[2] &gt; 1, 1, 0)
}
colnames(coefs_b) &lt;- c("x", "z")
coefs_b &lt;- as.data.frame(coefs_b)
```
]
.panel[.panel-name[Results]

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Predictor &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Coverage &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Bias &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; x &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.322 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.3062821 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;img src="selection-bias_files/figure-html/plot-ex1b-1.png" width="70%" style="display: block; margin: auto;" /&gt;
]
]
---
class:middle

.pull-left[

Estimating model parameters in the same single random sample used to find an appropriate model isn’t a good idea.

Discarding `\(z\)` from our model has distorted the sampling distribution of `\(x\)`.

&gt; "When a single model is not specified before the analysis begins, it is not clear what population parameter is the subject of study. And without this clarity, the reasoning behind statistical inference becomes obscure". (Berk et al., 2010)

]

.pull-right[


&lt;img src="selection-bias_files/figure-html/unnamed-chunk-1-1.png" width="100%" style="display: block; margin: auto;" /&gt;

]
---

# Known issues

.v-center[

`\begin{equation}
SE(\hat{\beta}_{yx\cdot z}) = \frac{\hat{\sigma_{\varepsilon}}}{s_x \sqrt{n-1}}\sqrt{\frac{1}{1-r^2_{xz}}} 
\end{equation}`

- Collinearity

- Noise: `\(\frac{S}{N} = \textbf{b}\Sigma\textbf{b}\sigma_{\varepsilon}^{-2}\)`

- Sample size ($n$)

- Number of candidate predictor variables (p)
]
---
class: scrollable-slide


```r
sim_bias_multi &lt;- function(reps, p, n, SNR, b, corr) {
  
  
  Sigma &lt;- matrix(corr, p, p)
  diag(Sigma) &lt;- 1
  beta &lt;- rep(b, p)
  names(beta) &lt;- paste0("x", 1:p)
  b0 &lt;- 1
  sigma_error &lt;-  sqrt(as.numeric(crossprod(beta, Sigma %*% beta) / SNR))
  
  rsq &lt;- NULL
  coefs &lt;- tvals &lt;- matrix(NA, nrow = reps, ncol = p)
  cover &lt;- matrix(0, nrow = reps, ncol = p)
  colnames(coefs) &lt;- paste0("x", 1:p)
  colnames(cover) &lt;- paste0("x", 1:p)
  colnames(tvals) &lt;- paste0("x", 1:p)
  
  for (i in seq(reps)) {
    
    X &lt;-  MASS::mvrnorm(n = n, rep(0, p) , Sigma)
    y &lt;- as.numeric(cbind(1, X) %*% c(b0, beta) + rnorm(n, 0, sigma_error))
    Xy &lt;- as.data.frame( cbind(X, y))
    colnames(Xy) &lt;- c(paste0("x", 1:p), "y")
    fit &lt;- lm(y ~., data = Xy)
    sel &lt;- step(fit, k = 2, trace = FALSE)
    s &lt;- summary(sel)
    tval &lt;- s$coefficients[,3][-1]
    tvals[i, names(tval)] &lt;-  tval
    coefs[i, names(tval)] &lt;- coef(sel)[-1]
    rsq[i] &lt;- s$r.squared
    cis &lt;- confint(sel)[-1,]
    if (length(cis) &lt; 3) {
      cover[i,names(tval)] &lt;- ifelse(cis[1] &lt; beta[names(tval)] &amp; 
                                       cis[2] &gt; beta[names(tval)], 1, 0)
    } else {
      cover[i,names(tval)] &lt;- ifelse(cis[names(tval),1] &lt; beta[names(tval)] &amp; 
                                       cis[names(tval),2] &gt; beta[names(tval)], 
                                     1, 0)
    }
    
  }
  
  res &lt;- list(coefs = coefs, tvals = tvals, cover = cover, 
              bias = coefs - beta, mse = (coefs - beta)^2, rsq = rsq, 
              corr = corr, p = p)
  
  res

}
```
---




```r
sims &lt;- furrr::future_map(seq(2, 10), 
                          ~furrr::future_pmap(
                            list(
                              reps = 1000, p = .x, n = 100, SNR = 0.5, 1, 
                              corr = seq(0.1, 0.9, by = 0.1)), sim_bias_multi))
```

&lt;img src="selection-bias_files/figure-html/simplots-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---
# To the app

https://marwin.shinyapps.io/model-selection-app/

&lt;a href="https://marwin.shinyapps.io/model-selection-app/"&gt;
   &lt;img alt="" src="img/app.jpg"
   width="800"&gt;
&lt;/a&gt;

---
# Conclusion
.v-center[
- We identified specific characteristics of the data generating model that can potentially increase the bias in estimates obtained through variable selection.

- Post-model-selection sampling distribution can deviate greatly from the assumed underlying distribution.

- Potential solutions:
  - Derive a theoretically based appropriate model 
  - Cross-validation (training and test sample)
  - Differentiate between confirmatory and exploratory analysis
]

---

# References
.small[
Berk, R. (2010). What you can and can’t properly do with regression. *Journal of Quantitative Criminology, 26*(4), 481–487. https://doi.org/10.1007/s10940-010-9116-4

Berk, R., Brown, L., Buja, A., Zhang, K., &amp; Zhao, L. (2013). Valid post-selection inference. *The Annals of Statistics, 41*(2), 802–837. https://doi.org/10.1214/12-AOS1077

Berk, R., Brown, L., &amp; Zhao, L. (2010). Statistical Inference After Model Selection. *Journal of Quantitative Criminology, 26*(2), 217–236. https://doi.org/10.1007/s10940-009-9077-7

Cohen, J., &amp; Cohen, P. (1983). *Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences* (2nd ed.).

Harrell, F. E. (2001). *Regression modeling strategies: With applications to linear models, logistic regression, and survival analysis*. Springer-Verlag, New York.

Lukacs, P. M., Burnham, K. P., &amp; Anderson, D. R. (2009). Model selection bias and Freedman's paradox. *Annals of the Institute of Statistical Mathematics, 62*(1), 117. https://doi.org/10.1007/s10463-009-0234-4
]
---
# Thank you

.pull-left[
Contact:
  - Email: [marwin@usp.br](mailto:marwin@usp.br)
  - Webpage: [https://marwincarmo.github.io/](https://marwincarmo.github.io/)
  - Github: [marwincarmo](https://github.com/marwincarmo)
  - Twitter: [marwincarmo](https://twitter.com/marwincarmo)
  - Linkedin: [Marwin Carmo](https://www.linkedin.com/in/marwin-carmo/)

This presentation was created using `xaringanthemer` package for R. Code available at https://github.com/marwincarmo/conferences/tree/main/vi-ser
]

.pull-right[
&lt;center&gt;
Access the slides at

&lt;img src="img/qrcodeSER.svg" width="70%" style="display: block; margin: auto;" /&gt;


&lt;a href="https://bit.ly/ser-selbias"&gt;bit.ly/ser-selbias&lt;/a&gt;

&lt;/center&gt;
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": false,
"scroll": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
